# UiFlou - DesafÃ­o TÃ©cnico Computer Vision

Soluciones a problemas de procesamiento de video, streaming RTSP y arquitectura multiagente.

## ðŸ“¦ InstalaciÃ³n

```bash
# Crear entorno virtual
python -m venv venv

# Activar (Windows)
.\venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt
```

## â˜ï¸ ConfiguraciÃ³n AWS
Para habilitar la subida de archivos a S3 (utilizado en Problema 1), es necesario configurar las siguientes variables de entorno. Puedes hacer esto en tu terminal o setearlas en tu sistema.

**Variables requeridas:**
- `AWS_ACCESS_KEY_ID`: Tu access key ID
- `AWS_SECRET_ACCESS_KEY`: Tu secret access key
- `AWS_REGION`: RegiÃ³n de AWS (ej: `us-east-1`)

**ConfiguraciÃ³n Powershell:**
```powershell
$env:AWS_ACCESS_KEY_ID="TU_ACCESS_KEY"
$env:AWS_SECRET_ACCESS_KEY="TU_SECRET_KEY"
$env:AWS_REGION="us-east-1"
```

> **Nota:** El nombre del bucket se define normalmente en `config.json` dentro del directorio del problema.

## ðŸš€ Uso

```bash
python launcher.py
```

El launcher ofrece una interfaz grÃ¡fica (GUI) para gestionar todos los desafÃ­os.

**CaracterÃ­sticas del Launcher:**
- **SelecciÃ³n de Video:** Permite elegir un archivo MP4. Si no se selecciona ninguno, los problemas intentarÃ¡n usar la webcam por defecto.
- **Botones Dedicados:** Un botÃ³n para cada problema (1, 2, 3 y 4).
- **EjecuciÃ³n Independiente:** Cada problema se ejecuta en su propio proceso, manteniendo la consola libre para logs.

> **Nota:** El "Problema 3" ignora la selecciÃ³n de video del launcher ya que se configura vÃ­a `config.yaml`. El "Problema 4" estÃ¡ diseÃ±ado para usar siempre la webcam directamente.

---

## Problema 1: Procesamiento de Video

**Objetivo:** Pose estimation + HAR + Tracking + Ãngulos + Export S3

### Herramientas
| Componente | TecnologÃ­a |
|------------|------------|
| Pose Estimation | YOLOv8-Pose |
| HAR | Ventana temporal 9s + clasificaciÃ³n |
| Tracking | ByteTrack (integrado YOLO) |
| Ãngulos | CÃ¡lculo geomÃ©trico keypoints |
| Export | JSON cada 1s + Video MP4 |
| Storage | AWS S3 (boto3) |

### EjecuciÃ³n Manual
```bash
cd "Problema 1"
# Usar video
python main.py video.mp4

# Usar webcam (por defecto)
python main.py
```

> **Nota:** Al iniciar y finalizar, el script puede preguntar si deseas limpiar los archivos JSON generados anteriormente.

---

## Problema 2: Streaming RTSP

**Objetivo:** Pose estimation + Object detection sobre stream RTSP

### Herramientas
| Componente | TecnologÃ­a |
|------------|------------|
| Object Detection | YOLOv8n + Tracking |
| Pose Estimation | YOLOv8-Pose + Tracking |
| Video Output | MP4 (H.264) |
| Data Output | JSON por frame |

### Estructura del Sistema
```
Problema 2/
â”œâ”€â”€ main.py              # Entry point
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ detector.py      # Object detection + tracking
â”‚   â”œâ”€â”€ pose_estimator.py # Pose + tracking
â”‚   â”œâ”€â”€ video_writer.py  # Export video
â”‚   â””â”€â”€ data_exporter.py # Export JSON
â”œâ”€â”€ output/              # JSONs
â””â”€â”€ video_outputs/       # Videos procesados
```

### Formato de Video
- **Codec:** H.264
- **Container:** MP4
- **ResoluciÃ³n:** Original del source

### Formato de Datos
```json
{
  "frame_id": 0,
  "detections": [{"class": "person", "conf": 0.95, "bbox": [...], "track_id": 1}],
  "poses": [{"keypoints": [...], "track_id": 1}]
}
```

### EjecuciÃ³n Manual
```bash
cd "Problema 2"

# RTSP Stream
python main.py --source rtsp://usuario:password@ip:port/stream

# Video Local
python main.py --source video.mp4

# Webcam (default)
python main.py
```

**Argumentos Adicionales:**
- `--no-display`: Ejecuta sin mostrar ventana (headless).
- `--output-dir`: Cambiar directorio de JSONs.
- `--video-output-dir`: Cambiar directorio de video.

---

## Problema 3: Streaming MulticÃ¡mara

**Objetivo:** Sistema de streaming para mÃºltiples cÃ¡maras RTSP (mÃ­n. 3)

### Herramientas
| Componente | TecnologÃ­a |
|------------|------------|
| Streaming | OpenCV + Threading |
| Config | YAML dinÃ¡mico |
| API REST | FastAPI + Uvicorn |
| Display | Grid layout OpenCV |

### Estructura
```
Problema 3/
â”œâ”€â”€ main.py           # Entry point
â”œâ”€â”€ camera_manager.py # GestiÃ³n de cÃ¡maras
â”œâ”€â”€ camera_stream.py  # Stream individual
â”œâ”€â”€ api.py            # REST API
â””â”€â”€ config.yaml       # ConfiguraciÃ³n
```

### ModificaciÃ³n de ParÃ¡metros en Runtime
**SoluciÃ³n propuesta:** REST API (FastAPI)
- `GET /cameras` - Listar cÃ¡maras activas
- `POST /cameras` - Agregar cÃ¡mara
- `DELETE /cameras/{id}` - Remover cÃ¡mara
- `PUT /cameras/{id}/params` - Modificar parÃ¡metros
- `POST /recording/start` - Iniciar grabaciÃ³n
- Hot-reload de `config.yaml` con tecla 'r'

### Â¿Real-time o Near Real-time?
**Near Real-time.** Razones:
1. **Buffering OpenCV:** Latencia de ~50-200ms por decode
2. **Threading overhead:** SincronizaciÃ³n entre streams
3. **Network latency:** RTSP agrega ~100-500ms
4. **Display sync:** Grid rendering introduce delay

Para real-time estricto se requerirÃ­a: GStreamer, hardware decode (NVDEC), zero-copy buffers.

### EjecuciÃ³n Manual
```bash
cd "Problema 3"
python main.py --config config.yaml
```

**Teclas en Runtime:**
- `q`: Salir
- `r`: Recargar configuraciÃ³n (Hot-reload de `config.yaml`)

**Argumentos:**
- `--no-api`: Desactiva el servidor REST.
- `--no-display`: Ejecuta sin interfaz grÃ¡fica.

---

## Problema 4: Agentes

Este desafÃ­o consta de dos partes: una **propuesta teÃ³rica** para un sistema completo y una **implementaciÃ³n simplificada** de un solo agente.

### ðŸ§  Parte A: Propuesta TeÃ³rica (Arquitectura)
*Respuesta a: Â¿QuÃ© agentes usarÃ­as? Â¿QuÃ© arquitectura? Â¿QuÃ© tecnologÃ­as?*

Para un entorno productivo real, propongo una arquitectura distribuida y desacoplada:

**1. Agentes Propuestos:**
*   **Safety Agent:** Detecta EPP (casco, chaleco, gafas) y zonas prohibidas.
*   **Ergonomics Agent:** Analiza posturas (Ã¡ngulos de espalda, repeticiÃ³n de movimientos) para prevenir lesiones.
*   **Workflow Agent:** Identifica herramientas en uso y mide tiempos de ciclo (Time-Motion study).
*   **Quality Agent:** InspecciÃ³n visual del resultado del trabajo (si es visible).

**2. Arquitectura Multiagente:**
DiseÃ±o basado en **Orquestador + Micro-agentes**:

```mermaid
graph TD
    Input[Stream CÃ¡mara] --> Orchestrator
    Orchestrator -->|Frame Routing| Safety[Safety Agent]
    Orchestrator -->|Frame Routing| Ergo[Ergonomics Agent]
    Orchestrator -->|Frame Routing| Tools[Workflow Agent]
    
    Safety -->|Events| PubSub[Redis / Queue]
    Ergo -->|Events| PubSub
    Tools -->|Events| PubSub
    
    PubSub --> AlertSystem[Sistema Alertas]
    PubSub --> Dashboard[Analytics Dashboard]
```

**3. Stack TecnolÃ³gico Sugerido:**
*   **OrquestaciÃ³n:** Ray (ideal para workloads distribuidos de CV/ML) o Apache Storm/Flink para procesamiento de streams.
*   **ComunicaciÃ³n:** Redis Streams o RabbitMQ (baja latencia).
*   **Modelos:**
    *   *YOLOv8-Pose* (ErgonomÃ­a)
    *   *YOLOv8-World* (DetecciÃ³n open-vocabulary de herramientas)
    *   *MediaPipe* (Gestos finos de manos)

---

### ðŸ’» Parte B: ImplementaciÃ³n de Ejemplo (Agente Simple)
*Respuesta a: CÃ³digo de ejemplo de un agente (muy simple)*

Como solicita el enunciado ("cÃ³digo muy simple"), se implementÃ³ un script monolÃ­tico (`simple_agent.py`) que condensa capacidades bÃ¡sicas en un solo proceso. **No es la arquitectura completa**, sino una demostraciÃ³n de capacidades de bajo nivel.

**Capacidades del Demo:**
*   **DetecciÃ³n de Manos:** MediaPipe Hands (Coord. 21 puntos).
*   **DetecciÃ³n de Pose:** MediaPipe Pose (Esqueleto completo).
*   **DetecciÃ³n de Objetos:** YOLOv8 Nano (Personas, botellas, herramientas).
*   **LÃ³gica de Negocio (Mock):** `check_safety_rules()` simula alertas si detecta manos o falta de operador.

**EjecuciÃ³n:**
```bash
cd "Problema 4"
# Requiere webcam
python simple_agent.py
```


### ðŸ“ Trazabilidad y Artifacts (.md)
Es fundamental guardar las bitacoras generadas por los agentes (archivos `.md`) para mantener una trazabilidad completa de las acciones realizadas. Esto permite:
1.  **AuditorÃ­a de Decisiones:** Entender por quÃ© un agente tomÃ³ cierta decisiÃ³n en un momento dado.
2.  **Contexto para Futuros Agentes:** Un agente puede leer estos archivos para comprender el contexto histÃ³rico, identificar problemas previos y evitar repetir errores, mejorando la continuidad del desarrollo.

## ðŸ“‹ Dependencias Consolidadas

```txt
ultralytics>=8.0.0
opencv-python>=4.8.0
numpy>=1.24.0
boto3>=1.28.0
pyyaml>=6.0
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.0.0
mediapipe>=0.10.21
```
